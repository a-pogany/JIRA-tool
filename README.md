# JIRA Ticket Generator

> **Transform unstructured text into production-ready Jira tickets using AI-powered extraction**

Convert meeting notes, design discussions, bug reports, or any text into comprehensive, first-class Jira tickets with complete specifications, acceptance criteria, and production-ready details.

**Status**: Phase 1 âœ… **PRODUCTION READY** | Phase 2 â­ï¸ Planned

---

## ğŸš€ Quick Start

### 1. Install

```bash
git clone https://github.com/a-pogany/JIRA-tool.git
cd JIRA-tool
pip install -r requirements.txt
```

### 2. Configure

```bash
cp .env.example .env
# Edit .env with your API keys:
# - OPENAI_API_KEY or ANTHROPIC_API_KEY
# - JIRA credentials (optional for Phase 1)
```

### 3. Generate Tickets

```bash
# Validate configuration
python3 jira_gen.py validate

# Extract tickets from text
python3 jira_gen.py parse your_notes.txt --project PROJ

# Or from clipboard
python3 jira_gen.py parse --clipboard --issue-type bug --project PROJ
```

**That's it!** The tool will extract structured, high-quality Jira tickets from your text.

---

## ğŸ“‹ What You Get

**Input:**
```
Build user authentication system. Users should be able to
login with email and password. Add password reset via email.
Make sure to add rate limiting to prevent brute force attacks.
```

**Output:** âœ¨
```
Epic: User Authentication System
â”œâ”€ Task 1: Implement login endpoint with JWT authentication
â”‚  â”œâ”€ Acceptance Criteria (7+):
â”‚  â”‚  â€¢ Functional: POST /api/auth/login accepts email and password
â”‚  â”‚  â€¢ Security: Rate limiting of 5 attempts per minute per IP
â”‚  â”‚  â€¢ Error: Invalid credentials return 401 with message
â”‚  â”‚  â€¢ Performance: Login completes within 200ms
â”‚  â”‚  â€¢ Testing: Unit tests for token generation
â”‚  â”‚  â€¢ Edge: Handles SQL injection attempts safely
â”‚  â”‚  â€¢ Edge: Rejects missing fields
â”‚  â””â”€ Technical Notes: bcrypt, JWT, httpOnly cookies
â””â”€ Task 2: Implement password reset functionality
   â””â”€ Acceptance Criteria (6+): ...
```

---

## âœ¨ Key Features

### Phase 1 (âœ… Available Now)

- âœ… **AI-Powered Extraction**: Uses OpenAI/Anthropic to extract structured tickets
- âœ… **4 Issue Types**: Tasks/Epics, Bug Reports, User Stories, Epic-only planning
- âœ… **High-Quality Output**: 6-8 acceptance criteria per task (exceeds requirements!)
- âœ… **LLM Fallback**: Works without LLM using simple extraction
- âœ… **Multiple Input Sources**: Files, clipboard, stdin
- âœ… **Comprehensive Details**: Security, performance, testing, edge cases

### Phase 2 (â­ï¸ Coming Soon)

- â­ï¸ **Review Agent**: Validates completeness and asks clarifying questions
- â­ï¸ **Markdown Output**: Human-editable intermediate format
- â­ï¸ **Jira Integration**: Direct upload to Jira with proper linking
- â­ï¸ **Interactive Q&A**: Fill gaps through conversation

---

## ğŸ“– User Guide

### Issue Types

The tool supports 4 different Jira issue types via `--issue-type`:

#### 1. Tasks/Epics (default)
Best for: Feature development, new functionality

```bash
python3 jira_gen.py parse feature.txt --issue-type task --project PROJ
```

**Creates:**
- Epics with business value
- Tasks with 6-8 acceptance criteria
- Technical specifications
- Security and performance requirements

**Example Input:**
```
Build a dashboard for analytics. Users need to see key metrics,
charts, and export data. Support filtering by date range.
```

#### 2. Bug Reports
Best for: Defect tracking, issue reporting

```bash
python3 jira_gen.py parse bug.txt --issue-type bug --project PROJ
```

**Creates:**
- Bug summary with clear title
- Detailed reproduction steps
- Environment information
- Severity and priority assessment

**Example Input:**
```
Login button doesn't work on Safari iOS. When users click it,
nothing happens. Steps: 1) Open Safari iOS 15+, 2) Go to login page,
3) Click button, 4) No action occurs.
```

#### 3. User Stories
Best for: Agile workflows, user-centric features

```bash
python3 jira_gen.py parse story.txt --issue-type story --project PROJ
```

**Creates:**
- "As a / I want to / So that" format
- Acceptance criteria in Given/When/Then format
- Priority and effort estimation

**Example Input:**
```
Users need to reset their password if they forget it.
They should receive an email with a reset link.
```

#### 4. Epic-Only
Best for: High-level planning without detailed tasks

```bash
python3 jira_gen.py parse epic.txt --issue-type epic-only --project PROJ
```

**Creates:**
- High-level epics with business value
- Associated tasks with requirements
- Strategic overview

---

### Configuration

Edit `.env` file with your settings:

```bash
# Required for LLM extraction (choose one)
LLM_PROVIDER=openai              # or 'anthropic'
OPENAI_API_KEY=sk-...            # Get from platform.openai.com
ANTHROPIC_API_KEY=sk-ant-...     # Get from console.anthropic.com
LLM_MODEL=gpt-4-turbo            # or 'claude-3-opus-20240229'

# Optional (for Phase 2)
JIRA_URL=https://your-domain.atlassian.net
JIRA_EMAIL=your-email@example.com
JIRA_API_TOKEN=your-api-token

# Optional
DEFAULT_PROJECT_KEY=PROJ          # Default project for tickets
```

**Validate configuration:**
```bash
python3 jira_gen.py validate
```

---

### CLI Commands

#### `parse` - Extract tickets from text

```bash
python3 jira_gen.py parse [INPUT_FILE] [OPTIONS]
```

**Options:**
- `--issue-type, -t`: Type of tickets (task|bug|story|epic-only) [default: task]
- `--project, -p`: Jira project key (e.g., PROJ)
- `--clipboard`: Read from clipboard instead of file
- `--skip-review`: Skip Agent 2 review (Phase 2 feature)

**Examples:**
```bash
# From file with default settings
python3 jira_gen.py parse notes.txt --project PROJ

# Bug report from clipboard
python3 jira_gen.py parse --clipboard --issue-type bug --project PROJ

# User story with specific project
python3 jira_gen.py parse story.txt --issue-type story --project MYAPP
```

#### `validate` - Check configuration

```bash
python3 jira_gen.py validate
```

Shows current configuration and validates API keys.

---

### Input Sources

#### From File
```bash
python3 jira_gen.py parse meeting_notes.txt --project PROJ
```

#### From Clipboard
```bash
python3 jira_gen.py parse --clipboard --issue-type task --project PROJ
```

Requires: `pip install pyperclip`

#### From Stdin (coming soon)
```bash
echo "Build login system" | python3 jira_gen.py parse --project PROJ
```

---

## ğŸ¯ Quality Standards

Every generated ticket includes:

| Aspect | Phase 1 Output | Example |
|--------|---------------|---------|
| **Acceptance Criteria** | 6-8 per task | "Functional: POST /api/auth/login returns JWT tokens" |
| **Security** | Always included | "Rate limiting of 5 attempts per minute per IP" |
| **Performance** | Quantified metrics | "Login request completes within 200ms" |
| **Error Handling** | Exact messages | "Invalid credentials return 401 with 'Invalid email or password'" |
| **Testing** | Explicit requirements | "Unit tests for token generation and validation" |
| **Edge Cases** | Multiple scenarios | "Handles SQL injection attempts safely" |
| **Technical Details** | Specific technologies | "Use bcrypt, JWT with 15min expiry, httpOnly cookies" |

**Quality Metrics (from testing):**
- âœ… Acceptance Criteria: 6-8 per task (target: â‰¥5)
- âœ… Specificity: High (exact APIs, error messages)
- âœ… Security: Always present
- âœ… Performance: Quantified metrics
- âœ… Test Coverage: Explicit requirements

---

## ğŸ—ï¸ Architecture

### Phase 1 (Current)

```
User Input (text file, clipboard)
         â†“
Configuration Validation (.env)
         â†“
Agent 1: Extraction Agent
  â€¢ Select prompt by issue type
  â€¢ Call LLM (OpenAI/Anthropic)
  â€¢ Parse JSON response
  â€¢ Convert to Pydantic models
  â€¢ Fallback mode if LLM fails
         â†“
TicketStructure (models.py)
  â€¢ Epics (with nested Tasks)
  â€¢ Bugs (with reproduction steps)
  â€¢ Stories (agile format)
         â†“
Console Output Display
  â€¢ Formatted for readability
  â€¢ All acceptance criteria shown
```

### Phase 2 (Planned)

```
         â†“
Agent 2: Review Agent
  â€¢ Validate completeness
  â€¢ Identify gaps
  â€¢ Ask clarifying questions
         â†“
User Interactive Q&A Session
         â†“
Markdown Generation
  â€¢ Timestamped files
  â€¢ Human-editable format
         â†“
Jira API Upload
  â€¢ Create epics and tasks
  â€¢ Link relationships
```

---

## ğŸ“‚ Project Structure

```
jira-tool/
â”œâ”€â”€ jira_gen.py              # âœ… Main CLI (parse, validate)
â”œâ”€â”€ config.py                # âœ… Configuration management
â”œâ”€â”€ models.py                # âœ… Pydantic models (Task, Epic, Bug, Story)
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ extraction_agent.py  # âœ… Agent 1: LLM extraction
â”‚   â”œâ”€â”€ prompts.py           # âœ… Prompts for all issue types
â”‚   â””â”€â”€ review_agent.py      # â­ï¸ Agent 2 (Phase 2)
â”‚
â”œâ”€â”€ .env                     # âœ… Your configuration (gitignored)
â”œâ”€â”€ .env.example             # âœ… Configuration template
â”œâ”€â”€ requirements.txt         # âœ… Dependencies
â”‚
â”œâ”€â”€ test_*.txt               # âœ… Sample test inputs
â”œâ”€â”€ PHASE1_STATUS.md         # âœ… Implementation status
â”œâ”€â”€ TEST_REPORT.md           # âœ… Test results (16/16 passed!)
â”‚
â””â”€â”€ jira_client.py           # â­ï¸ Jira API (Phase 2)
```

---

## ğŸ§ª Testing

**Phase 1 Test Results**: âœ… 16/16 tests passed (100%)

```bash
# Run validation
python3 jira_gen.py validate

# Test with sample inputs
python3 jira_gen.py parse test_input.txt --project TEST
python3 jira_gen.py parse test_bug.txt --issue-type bug --project TEST
python3 jira_gen.py parse test_story.txt --issue-type story --project TEST
```

See [TEST_REPORT.md](TEST_REPORT.md) for comprehensive test results.

---

## ğŸ“š Documentation

- **[DESIGN.md](DESIGN.md)**: Complete architecture specification
- **[PHASE1_STATUS.md](PHASE1_STATUS.md)**: Implementation status tracking
- **[TEST_REPORT.md](TEST_REPORT.md)**: Comprehensive testing results
- **[prj-definition.md](prj-definition.md)**: Original project requirements

---

## ğŸ”§ Development

### Running Tests

```bash
# Phase 1: Manual testing
python3 jira_gen.py parse test_input.txt --project TEST

# Phase 2: Automated test suite (coming soon)
pytest tests/
```

### Dependencies

```bash
pip install -r requirements.txt
```

**Required:**
- click>=8.1.0 (CLI framework)
- pydantic>=2.5.0 (Data models)
- python-dotenv>=1.0.0 (Configuration)
- openai>=1.3.0 (OpenAI LLM)
- anthropic>=0.7.0 (Anthropic LLM)

**Optional:**
- pyperclip>=1.8.2 (Clipboard support)

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests to ensure quality
5. Commit (`git commit -m 'Add amazing feature'`)
6. Push (`git push origin feature/amazing-feature`)
7. Open a Pull Request

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

---

## ğŸ¯ Roadmap

### âœ… Phase 1 (Complete)
- âœ… Core configuration and data models
- âœ… Extraction Agent with LLM integration
- âœ… Support for 4 issue types
- âœ… High-quality output (6-8 acceptance criteria)
- âœ… Comprehensive testing (16/16 passed)

### â­ï¸ Phase 2 (Planned)
- â­ï¸ Review Agent for validation
- â­ï¸ Interactive Q&A session
- â­ï¸ Markdown generation
- â­ï¸ Jira API integration
- â­ï¸ Automated test suite

---

## ğŸ’¡ Tips & Best Practices

### Writing Better Input

**Good Input:**
```
Build user authentication system. Users need to login with email/password.
Add password reset via email. Security is important - prevent brute force.
Store passwords securely. Performance should be fast (< 200ms).
```

**Why it works:**
- Clear requirements
- Mentions security
- Includes performance expectations
- Specific features listed

**Output Quality:**
- Will generate 6-8 acceptance criteria
- Includes security requirements (rate limiting, bcrypt)
- Performance metrics specified
- Edge cases covered

### Issue Type Selection

| If you have... | Use | Creates |
|---------------|-----|---------|
| Feature ideas, requirements | `--issue-type task` | Epics + detailed Tasks |
| Bug description | `--issue-type bug` | Bug report with reproduction |
| User needs | `--issue-type story` | Agile user stories |
| High-level initiatives | `--issue-type epic-only` | Strategic epics |

---

## â“ FAQ

**Q: Do I need an LLM API key?**
A: Highly recommended for quality output, but the tool has a fallback mode that works without LLM.

**Q: Which LLM provider is better?**
A: Both OpenAI and Anthropic work well. GPT-4 Turbo is currently the default.

**Q: How much does it cost?**
A: Depends on your LLM provider. Typical extraction uses ~1-2K tokens per request ($0.01-0.02 with GPT-4 Turbo).

**Q: Can I use this without Jira?**
A: Yes! Phase 1 works standalone. Phase 2 will add Jira integration.

**Q: What's the quality like?**
A: Excellent. Testing shows 6-8 acceptance criteria per task with specific technical details. See [TEST_REPORT.md](TEST_REPORT.md).

**Q: Is Phase 2 coming soon?**
A: Yes! Agent 2, markdown generation, and Jira API integration are planned.

---

## ğŸ™ Acknowledgments

- AI-powered extraction using OpenAI and Anthropic models
- Inspired by the need for high-quality, complete Jira tickets
- Focus on developer autonomy - tickets so complete no questions needed

---

**Built with focus on first-class quality, zero ambiguity, and production-ready specifications** ğŸ¯
